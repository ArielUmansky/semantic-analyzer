== README

Welcome to the semantic analyzer service that clusters spanish texts.
This service is still under development so the documentation will be updated according to the advancements.

=== API

This service exposes a REST API. The followings are the supported endpoints so far:

====POST /analyzer
 
This route clusters data that should be specified in the body of the request. Also the client can configure the algorithm used by the analyzer and the metadata of the corpus.

The service is implemented in such a way that will be easy to add new algorithms in the future. 

The body admits the following parameters:

    {   
     algorithm: ... // Optional. Should be one of the algorithms supported.
               The service uses Kmeans by default if the client doesn't specify any
               
     metadata: ... // Should be a hash including metadata for the algorithm used. 
             Each algorithm specifies its own metadata
             
     corpus: [ 
              {
                document: "Here goes the text of the document. 
                      All the documents must have it", 
                      
                category: "optional_category_string", 
                
                keywords: ["optional", "array", "of", "keywords", "that", "are", 
                      "important", "for", "this", "document"],
                      
                user_info: ... // Optional. This will be by-passed and be returned in the response. 
                                   We recomend to use it to identify each document later
               }, 
              
              ... 
              
              ]
    }
    
This is the structure of the body in the response in case of a successful scenario:

    {   
     result: [
              {
               grouped_documents: [
                                   {
                                     document: "document clustered",
                                     user_info: ... // The same info that was loaded by
                                                 the user in the request
                                    },
                                   
                                   ...
                                   
                                 ]
               },
               
               ...
               
             ]
    }

This is the structure of the body in the response in case of an error happens:

    {   
      error: "error_message"
    }

=====Generic Validations
* The number of centroids cannot be greater than the amount of documents in the corpus. 
* There must be at least two documents in the request
* The user cannot set identical documents in the equest
    
The algorithms supported so far are: 

* kmeans

=====KMeans

Kmeans is one of the most common algorithms of machine learning. This service uses it togheter with cosine similarity and tf-idf to model the documents and cluster them.

This algorithm requires the amount of clusters before its execution. Therefore, the client must specify that in one of the following params in the metadata of the body:

    {
        nmb_of_centroids: ... // Should be a number specifying explicitly the number of clusters
        cluster_size: ... // Should be a number specifying an estimate of the size of each cluster.
                             With this data, the service can infer the number of clusters
    }

* Kmeans Validations*
* If the user doesn't specify one if this fields in the metadata, the user will receive HTTP Status 422: Unprocessable Entity. 




